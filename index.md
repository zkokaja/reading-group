# Reading Groups

List of papers and resources for the papers we're reading.

## NLP Summer 2020

We meet Thursdays at 10:00

| Date | Paper | 
| ---- | ----- | 
| 7/9  | [Attention is not not Explanation](https://arxiv.org/pdf/1908.04626.pdf)
| 6/25 | [Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain)](https://arxiv.org/pdf/1905.11833.pdf)
| 6/18 | [Generating Long Sequences with Sparse Transformers](https://arxiv.org/pdf/1904.10509.pdf)
| 6/11 | [UNITER: UNiversal Image-TExt Representation Learning](https://arxiv.org/pdf/1909.11740.pdf)
| 6/4  | [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)

## NLP Spring 2020

| Date | Paper | 
| ---- | ----- |
| 5/28 | [Robust and Scalable Differentiable Neural Computer for Question Answering](https://www.aclweb.org/anthology/W18-2606.pdf)
| 5/21 | [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)
| 5/14 | [WT5?! Training Text-to-Text Models to Explain their Predictions](https://arxiv.org/pdf/2004.14546.pdf)
| 5/7  | [Deep Communicating Agents for Abstractive Summarization](https://www.aclweb.org/anthology/N18-1150.pdf)
| 4/30 | [Pay Less Attention with Lightweight and Dynamic Convolutions](https://openreview.net/pdf?id=SkVhlh09tX)
| 4/23 | [The Evolved Transformer](https://arxiv.org/pdf/1901.11117.pdf)
| 4/16 | [ERNIE](https://arxiv.org/pdf/1905.07129.pdf) and [ERNIE 2.0](https://arxiv.org/pdf/1907.12412.pdf)
| 4/9  | [Meena](https://arxiv.org/abs/2001.09977)
| 4/2  | [Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)
| 3/26 | [BART](https://arxiv.org/pdf/1910.13461.pdf)
| 3/19 | [Multi-task Learning with Multi-head Attention for Multi-choice Reading Comprehension](https://arxiv.org/pdf/2003.04992.pdf)
| 3/12 | [A Primer in BERTology: What we know about how BERT works](https://arxiv.org/pdf/2002.12327.pdf)
| 3/5  | [Compressive Transfomers for Long-Range Sequence Modelling](https://arxiv.org/abs/1911.05507) 
